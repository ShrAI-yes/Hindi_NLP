{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64c22d05-ae5c-498d-9929-aec39753751d",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccf2dda1-35dc-4fad-99a7-54c5d720ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8601bc4e-8169-4ca0-8e07-e4a78d35727f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"LondonStory/txlm-roberta-hindi-sentiment\")\n",
    "sentimen_analysis_model = AutoModelForSequenceClassification.from_pretrained(\"LondonStory/txlm-roberta-hindi-sentiment\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e65f6c32-247b-4274-88e3-5ae9bf5dc382",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'हाँ-हाँ, मैं समझ गया। मैं पूरी कोशिश करूँगा।'\n",
    "encoded_input = tokenizer(input, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "accbeb0d-4032-4433-a0c9-ff0c7db21414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[     0, 131952,      9, 150858,      4,  10399,  41126,   5349,    125,\n",
       "          10399,  41060,  77711,  33675,   4739,  10307,    125,      2]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aa8a5cf-b885-429c-b662-88fb83229999",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = sentimen_analysis_model(**encoded_input).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59bc3f14-c0cd-44c6-ad7b-87c8b68fe23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LABEL_2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class_id = output.argmax().item()\n",
    "sentimen_analysis_model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5f0ea3-8ce0-4137-ab2e-e53b9b27fe90",
   "metadata": {},
   "source": [
    "Label 1- neg, Label 0- neutral, Label-2 pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a19da95-f0e7-4645-abea-bbe96ab643a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaConfig {\n",
       "  \"_name_or_path\": \"LondonStory/txlm-roberta-hindi-sentiment\",\n",
       "  \"architectures\": [\n",
       "    \"XLMRobertaForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\",\n",
       "    \"1\": \"LABEL_1\",\n",
       "    \"2\": \"LABEL_2\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0,\n",
       "    \"LABEL_1\": 1,\n",
       "    \"LABEL_2\": 2\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"xlm-roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"problem_type\": \"single_label_classification\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.32.1\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 250002\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimen_analysis_model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8f8b07-8aea-4b46-880d-0dfc3026a220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"LondonStory/txlm-roberta-hindi-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a149b40-8f5e-4e7f-8511-2bc13494a667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.516538679599762}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe('नमस्ते, मैं राजेश बोल रहा हूँ, CFI फाइनेंस कंपनी से। क्या मैं श्री सुरेश कुमार से बात कर सकता हूँ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43967d27-c6d4-44a4-8f6f-55c117c18744",
   "metadata": {},
   "source": [
    "# Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9537f8-9eb7-48af-a36a-0c159f9f503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "convo = '''Speaker 1: नमस्ते, मैं राजेश बोल रहा हूँ, CFI फाइनेंस कंपनी से। क्या मैं श्री सुरेश कुमार से बात कर सकता हूँ?\n",
    "Speaker 2: हाँ, मैं ही सुरेश बोल रहा हूँ। क्या बात है?\n",
    "Speaker 1: सुरेशजी, मैं आपके लोन के बारे में बात करने के लिए फोन कर रहा हूँ। आपका EMI पिछले तीन महीने से बकाया है।\n",
    "Speaker 2: अरे हाँ, मुझे पता है। लेकिन आप लोग हर रोज फोन करके परेशान कर रहे हैं। मैंने कहा था ना कि जैसे ही पैसे होंगे, मैं भर दूंगा।\n",
    "Speaker 1: देखिए सुरेशजी, हम समझते हैं आपकी परेशानी। लेकिन आप भी समझिए, यह हमारा काम है। आपको पता है कि आपके ऊपर कितना बकाया है?\n",
    "Speaker 2: हाँ-हाँ, मुझे अंदाजा है। लगभग 50,000 रुपये होंगे।\n",
    "Speaker 1: नहीं सुरेशजी, आप गलत हैं। आप पर कुल 75,000 रुपये बकाया है, जिसमें लेट फीस और ब्याज भी शामिल है।\n",
    "Speaker 2: क्या? इतने ज्यादा? यह कैसे हो सकता है? आप लोग लूट रहे हैं क्या?\n",
    "Speaker 1: देखिए सुरेशजी, गुस्सा करने से कुछ नहीं होगा। आपको समय पर पैसे जमा करने चाहिए थे। अब बताइए, कब तक आप यह राशि जमा कर सकते हैं?\n",
    "Speaker 2: अरे भाई, मेरी बात तो सुनो! मेरी माँ की तबीयत खराब है, अस्पताल में भर्ती हैं। सारे पैसे उनके इलाज में खर्च हो गए।\n",
    "Speaker 1:  सुरेशजी, मुझे आपकी परिस्थिति से कोई मतलब नहीं है। हमें बस अपना पैसा चाहिए। आप समझ रहे हैं या नहीं?\n",
    "Speaker 2: क्या बकवास कर रहे हो? तुम्हें शर्म नहीं आती? मेरी माँ मरने की कगार पर हैं और तुम पैसों की बात कर रहे हो?\n",
    "Speaker 1:  देखो सुरेश, मुझे तुम्हारी कहानियों से कोई फर्क नहीं पड़ता। तुमने लोन लिया है तो चुकाना पड़ेगा। समझे? वरना हम कानूनी कार्रवाई करेंगे।\n",
    "Speaker 2: तुम धमकी दे रहे हो? तुम्हें पता है मैं कौन हूँ? मैं तुम्हारी नौकरी गंवा सकता हूँ।\n",
    "Speaker 1:  अरे वाह! अब तुम भी धमकी दे रहे हो? चलो, देखते हैं कौन क्या कर सकता है। तुम अपनी माँ का इलाज करवाओ, मैं तुम्हारा इलाज करूँगा।\n",
    "Speaker 2: बदतमीज! तुम्हारी हिम्मत कैसे हुई ऐसे बात करने की? मैं तुम्हारे बॉस से शिकायत करूँगा।\n",
    "Speaker 1: करो जो करना है। लेकिन याद रखना, अगर कल तक पैसे नहीं आए तो मैं खुद तुम्हारे घर आऊंगा। और तब देखेंगे कौन किसका इलाज करता है।\n",
    "Speaker 2: तुम मेरे घर आओगे? ठीक है, आ जाओ। देखता हूँ कैसे आते हो। मैं पुलिस को बुला लूंगा।\n",
    "Speaker 1: अरे वाह! पुलिस? बहुत अच्छा। हम भी देखेंगे कि पुलिस किसका साथ देती है - एक कर्जदार का या एक कानूनी कंपनी का।\n",
    "Speaker 2: तुम... तुम बहुत बुरे इंसान हो। मेरी मजबूरी का फायदा उठा रहे हो।\n",
    "Speaker 1:  हाँ-हाँ, मैं बहुत बुरा हूँ। लेकिन तुमसे तो अच्छा ही हूँ। कम से कम मैं अपने वादे तो पूरे करता हूँ।\n",
    "Speaker 2: क्या मतलब? मैंने कभी वादा तोड़ा है क्या?\n",
    "Speaker 1: अरे सुरेश भाई, तुमने हर महीने EMI भरने का वादा किया था। वो क्या हुआ? भूल गए?\n",
    "Speaker 2:  देखो, मैं समझता हूँ। लेकिन अभी मेरे पास सच में पैसे नहीं हैं। क्या कोई और तरीका नहीं है?\n",
    "Speaker 1: तरीका तो है। लेकिन उसके लिए तुम्हें कुछ करना होगा।\n",
    "Speaker 2: क्या करना होगा? बताओ, मैं तैयार हूँ।\n",
    "Speaker 1: पहले तो अपनी माँ का इलाज बंद करो। उन पैसों से हमारा कर्ज चुका दो।\n",
    "Speaker 2:  क्या बकवास कर रहे हो? तुम पागल हो गए हो क्या?\n",
    "Speaker 1: अरे नहीं-नहीं, मैं तो मजाक कर रहा था। तुम तो बहुत जल्दी गुस्सा हो जाते हो।\n",
    "Speaker 2:  तुम्हें यह सब मजाक लगता है? मेरी जिंदगी बर्बाद हो रही है और तुम मजाक कर रहे हो?\n",
    "Speaker 1: अच्छा सुनो, मैं तुम्हें एक और मौका देता हूँ। कल तक 25,000 रुपये जमा कर दो। बाकी के लिए हम एक नया प्लान बना लेंगे।\n",
    "Speaker 2: 25,000? इतने पैसे कहाँ से लाऊँ मैं?\n",
    "Speaker 1: वो तुम्हारी समस्या है। चाहे दोस्तों से उधार लो, या फिर कुछ बेच दो। लेकिन कल तक पैसे चाहिए।\n",
    "Speaker 2: तुम समझ क्यों नहीं रहे हो? मेरे पास सच में पैसे नहीं हैं।\n",
    "Speaker 1: देखो सुरेश, मुझे लगता है तुम समझ नहीं रहे हो। अगर तुम कल तक पैसे नहीं देते, तो मैं तुम्हारे ऑफिस आऊंगा और सबके सामने तुम्हारी पोल खोल दूंगा।\n",
    "Speaker 2:  नहीं-नहीं, ऐसा मत करना। मेरी इज्जत का सवाल है।\n",
    "Speaker 1: तो फिर ठीक है। कल तक पैसे जमा कर दो। वरना तुम जानते हो क्या होगा।\n",
    "Speaker 2: ठीक है, मैं कोशिश करूँगा। लेकिन प्लीज, मेरे ऑफिस मत आना।\n",
    "Speaker 1: बहुत अच्छा। अब तुम समझदारी की बात कर रहे हो। याद रखना, कल शाम 5 बजे तक पैसे नहीं आए तो मैं सीधा तुम्हारे ऑफिस पहुँच जाऊंगा।\n",
    "Speaker 2: हाँ-हाँ, मैं समझ गया। मैं पूरी कोशिश करूँगा।\n",
    "Speaker 1: ठीक है। और हाँ, अगली बार जब लोन लो तो याद रखना - समय पर पैसे नहीं चुकाओगे तो ऐसे ही परेशान होना पड़ेगा।\n",
    "Speaker 2:  हाँ, मैं समझ गया। अब मैं रखता हूँ।\n",
    "Speaker 1: ठीक है। और याद रखना, कल शाम 5 बजे। एक मिनट की भी देरी हुई तो...\n",
    "Speaker 2: हाँ-हाँ, मैंने कहा ना मैं कोशिश करूँगा।\n",
    "Speaker 1: कोशिश नहीं, करना होगा। समझे? अच्छा, अब रखता हूँ। कल मिलते हैं - या तो बैंक में, या फिर तुम्हारे ऑफिस में।\n",
    "Speaker 2:  हाँ, ठीक है। नमस्ते।\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf1385d3-f5cd-4cb7-878a-007f00348c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ec67c05-f4bf-4b00-aa77-b57ef36f3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('convo.txt', \"r\", encoding=\"utf-8\") as f:\n",
    "    hindi_text = f.read()\n",
    "\n",
    "hindi_text = 'नमस्ते, मैं राजेश बोल रहा हूँ, CFI फाइनेंस कंपनी से। क्या मैं श्री सुरेश कुमार से बात कर सकता हूँ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c32d82b-94c2-42fb-997d-72210b9558cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    translator = googletrans.Translator()\n",
    "    english_text = translator.translate(hindi_text, dest=\"en\").text\n",
    "except Exception as e:\n",
    "    print(\"Translation failed:\", e)\n",
    "    english_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0bc1eaaa-7f78-48aa-97b4-61582f443a7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello, I am Rajesh from CFI Finance Company. Can I speak to Mr. Suresh Kumar?'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9cf36f-ea26-4e5f-a9c4-6bc04634f193",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "checkpoint = \"Jayveersinh-Raj/hindi-summarizer-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "summarizer_model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b00ebfc-b229-476b-a480-d56768d45bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\convert_slow_tokenizer.py:470: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "\n",
    "model_name = \"csebuetnlp/mT5_m2o_hindi_crossSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "sum_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5eede8d-b61c-4fd2-a730-4c39125bc520",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_text = 'सुरेशजी, मैं आपके लोन के बारे में बात करने के लिए फोन कर रहा हूँ। आपका EMI पिछले तीन महीने से बकाया है।'\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    [WHITESPACE_HANDLER(article_text)],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")[\"input_ids\"]\n",
    "\n",
    "output_ids = sum_model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=84,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams=4\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b5336d1e-26e2-4e0b-9fcc-db9b7ce3627d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([250021,    259,  21726,  22753,  15230,  32954,   9255,  10596,    641,\n",
       "         26980,   1462, 116277,  88306,  36086,  20976,    259,  30590,   1163,\n",
       "          1890,    259,    863,   2075,   1822,  36158,  19422,    757,    943,\n",
       "          2075,    830,    260,      1])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dbef257f-1f9b-4aae-a382-3b9d03642572",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = tokenizer.decode(\n",
    "    output_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "af0eae4f-2351-441c-b60c-767f1741da46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'भारतीय रिज़र्व बैंक के पूर्व गवर्नर सुरेश कुमार का एक नया बयान सामने आया है.'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975acfcd-9957-402c-8f2b-da2e2674e899",
   "metadata": {},
   "source": [
    "# NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8204361f-e3e4-4ca0-b9e9-9031ef85909f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc730624f4a4e0a99116007db479d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "590b2a48480b4ce2aeed382d848a6530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/948M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "B:\\Software\\Anaconda\\envs\\predixion\\lib\\site-packages\\transformers\\modeling_utils.py:479: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "462bd90dadd34c62ae817107bb8f047f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21979871953a4e1f898f71dc858126fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d66ad22fa4c41658e39efcf3d26987f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe870360ea774186ab59352c9f895a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "ner_model = AutoModelForTokenClassification.from_pretrained(\"MichaelHuang/muril_base_cased_hindi_ner\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n",
    "\n",
    "# Define the labels dictionary\n",
    "labels_dict = {\n",
    "    0: \"B-FESTIVAL\",\n",
    "    1: \"B-GAME\",\n",
    "    2: \"B-LANGUAGE\",\n",
    "    3: \"B-LITERATURE\",\n",
    "    4: \"B-LOCATION\",\n",
    "    5: \"B-MISC\",\n",
    "    6: \"B-NUMEX\",\n",
    "    7: \"B-ORGANIZATION\",\n",
    "    8: \"B-PERSON\",\n",
    "    9: \"B-RELIGION\",\n",
    "    10: \"B-TIMEX\",\n",
    "    11: \"I-FESTIVAL\",\n",
    "    12: \"I-GAME\",\n",
    "    13: \"I-LANGUAGE\",\n",
    "    14: \"I-LITERATURE\",\n",
    "    15: \"I-LOCATION\",\n",
    "    16: \"I-MISC\",\n",
    "    17: \"I-NUMEX\",\n",
    "    18: \"I-ORGANIZATION\",\n",
    "    19: \"I-PERSON\",\n",
    "    20: \"I-RELIGION\",\n",
    "    21: \"I-TIMEX\",\n",
    "    22: \"O\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76d7f2b4-488d-4a6c-be8d-16b257631b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"नमस्ते, मैं राजेश बोल रहा हूँ, CFI फाइनेंस कंपनी से। क्या मैं श्री सुरेश कुमार से बात कर सकता हूँ? हाँ, मैं ही सुरेश बोल रहा हूँ। क्या बात है?\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edcca585-eee6-4a0f-93c3-58e5f338d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "  output = ner_model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2da20ff1-3338-48fc-a703-58ab3249e97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = output.argmax(-1)\n",
    "\n",
    "\n",
    "labels = predicted_labels.squeeze().tolist()\n",
    "predicted_labels = [labels_dict[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd8b66e1-6317-4656-8ee0-fe12f71fbd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "राजेश: B-PERSON\n",
      "CF: B-ORGANIZATION\n",
      "##I: B-ORGANIZATION\n",
      "फाइनेंस: I-ORGANIZATION\n",
      "कंपनी: I-ORGANIZATION\n",
      "श्री: B-PERSON\n",
      "सुरेश: B-PERSON\n",
      "कुमार: I-PERSON\n",
      "सुरेश: B-PERSON\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
    "\n",
    "result = list(zip(tokens, predicted_labels))\n",
    "\n",
    "for token, label in result:\n",
    "  if label != \"O\":\n",
    "    print(f\"{token}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640fef-c8c9-4f42-bed0-814263985838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:predixion]",
   "language": "python",
   "name": "conda-env-predixion-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
